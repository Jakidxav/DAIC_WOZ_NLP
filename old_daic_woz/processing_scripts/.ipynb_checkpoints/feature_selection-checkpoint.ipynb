{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from clean_text import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists to append each transcript feature to\n",
    "#append participant number from filename for indexing\n",
    "participant_num = []\n",
    "#count total words, words per sentence\n",
    "total_words, wps = [], []\n",
    "#filler words, personal prnouns lists\n",
    "pronouns1, pronouns2, pronouns3 = [], [], []\n",
    "\n",
    "fillers, absolute_words = [], []\n",
    "\n",
    "#create lists containing fillers, pronouns\n",
    "filler_list = ['uh', 'uhhh', 'um', 'ummm', ]\n",
    "\n",
    "#source: https://en.wikipedia.org/wiki/English_personal_pronouns\n",
    "singular_list = ['i', \"i'm\", 'me', 'myself', 'mine', 'my']\n",
    "plural_list = ['we', 'us', 'ourselves', 'ourself', 'ours', 'our']\n",
    "third_list = ['he', 'him', 'himself', 'his', 'she', 'her', 'herself', 'hers', 'her',\n",
    "             'they', 'them', 'themselves', 'themself', 'theirs', 'their']\n",
    "\n",
    "#create list for absolutist words\n",
    "absolute_list = ['always', 'nothing', 'completely', 'never', 'all', 'every', 'none', 'only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change directory\n",
    "raw_text_dir = './Part/raw/'\n",
    "change_dir = os.chdir(raw_text_dir)\n",
    "\n",
    "#get current working directory\n",
    "this_dir = os.getcwd()\n",
    "filenames = os.listdir(this_dir)\n",
    "\n",
    "#sort filenames for sorting vectors\n",
    "filenames = sorted(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to iterate through documents\n",
    "#create a list of *strings*, each one containing the transcript of a participant\n",
    "for filename in filenames:\n",
    "    if filename.endswith('.txt'):\n",
    "        \n",
    "        #read in file contents\n",
    "        file = open(filename, 'rt')\n",
    "        text = file.read()\n",
    "        \n",
    "        #count sentences in file\n",
    "        sentence_count = count_sentences(filename)\n",
    "        \n",
    "        file.close()\n",
    "        \n",
    "        #add participant id number to list\n",
    "        participant_num.append(int(filename[:3]))\n",
    "            \n",
    "        #whitespace tokenize\n",
    "        tokens = tokenize(text)\n",
    "            \n",
    "        #count tokens here for total words\n",
    "        total = len(tokens)\n",
    "        total_words.append(total)\n",
    "            \n",
    "        #calculate words per sentence\n",
    "        average_words = total / sentence_count\n",
    "        wps.append(average_words)\n",
    "            \n",
    "        #now loop through fillers, pronouns, absolute words\n",
    "        fill = list_in_text(filler_list, tokens)\n",
    "        fillers.append(fill)\n",
    "        \n",
    "        single = list_in_text(singular_list, tokens)\n",
    "        pronouns1.append(single)\n",
    "        \n",
    "        plural = list_in_text(plural_list, tokens)\n",
    "        pronouns2.append(plural)\n",
    "        \n",
    "        third = list_in_text(third_list, tokens)\n",
    "        pronouns3.append(third)\n",
    "        \n",
    "        absolute = list_in_text(absolute_list, tokens)\n",
    "        absolute_words.append(absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save features to a dataframe\n",
    "features = pd.DataFrame({'id': participant_num,\n",
    "                        'num_words': total_words,\n",
    "                        'wps': wps,\n",
    "                        'fillers': fillers,\n",
    "                        'p1': pronouns1,\n",
    "                        'p2': pronouns2,\n",
    "                        'p3': pronouns3,\n",
    "                        'abs': absolute_words}, index=participant_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export dataframe to csv for later use\n",
    "features.to_csv('features.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
