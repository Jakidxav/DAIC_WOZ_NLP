{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Joshua Driscol\n",
    "\n",
    "\n",
    "### Introduction </br>\n",
    "\n",
    "This notebook is to test and demonstrate the helper methods I wrote as NLTK wrappers for the DAIC_WOZ NLP project. The goal of these functions is to clarify processing workflow by decluttering the workspace. All of the functions written in `clean_text.py` have the form: `output = function(input)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "from clean_text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example string\n",
    "example = \" This   &is [an] ExAmPlE? {of} 45 string. with.? punctuation, by stopwordS and whitespace.    Can't wait!!!!\"\n",
    "\n",
    "#create stop words set\n",
    "stops = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example processing flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whitespace tokenize, **preserve contractions**\n",
    "tokens = tokenize(example)\n",
    "\n",
    "#strip punctuation\n",
    "no_punct = strip_punctuation(tokens)\n",
    "\n",
    "#convert to lowercase\n",
    "lower = lower_case(no_punct)\n",
    "\n",
    "#remove stopwords\n",
    "no_stops = remove_stopwords(lower)\n",
    "\n",
    "#remove numbers from tokens\n",
    "words = remove_numbers(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This   &is [an] ExAmPlE? {of} 45 string. with.? punctuation, by stopwordS and whitespace.    Can't wait!!!! \n",
      "\n",
      "['This', '&is', '[an]', 'ExAmPlE?', '{of}', '45', 'string.', 'with.?', 'punctuation,', 'by', 'stopwordS', 'and', 'whitespace.', \"Can't\", 'wait!!!!'] \n",
      "\n",
      "['This', 'is', 'an', 'ExAmPlE', 'of', '45', 'string', 'with', 'punctuation', 'by', 'stopwordS', 'and', 'whitespace', 'Cant', 'wait'] \n",
      "\n",
      "['this', 'is', 'an', 'example', 'of', '45', 'string', 'with', 'punctuation', 'by', 'stopwords', 'and', 'whitespace', 'cant', 'wait'] \n",
      "\n",
      "['example', '45', 'string', 'punctuation', 'stopwords', 'whitespace', 'cant', 'wait'] \n",
      "\n",
      "['example', 'string', 'punctuation', 'stopwords', 'whitespace', 'cant', 'wait'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(example, '\\n')\n",
    "print(tokens, '\\n')\n",
    "print(no_punct, '\\n')\n",
    "print(lower, '\\n')\n",
    "print(no_stops, '\\n')\n",
    "print(words, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
