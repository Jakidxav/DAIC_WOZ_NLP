{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Joshua Driscol\n",
    "\n",
    "\n",
    "### Introduction </br>\n",
    "\n",
    "This notebook is to test and demonstrate the helper methods I wrote as NLTK wrappers for the DAIC_WOZ NLP project. The goal of these functions is to clarify processing workflow by decluttering the workspace. All of the functions written in `clean_text.py` have the form: `output = function(input)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "from clean_text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example string\n",
    "example = \"<semantics> This   &is [an] ExAmPlE? {of} 45 string. with.? <sigh> [] punctuation, [laugh] by stopwordS and whitespace.    Can't wait!!!!\"\n",
    "\n",
    "#create stop words set\n",
    "stops = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example processing flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whitespace tokenize, **preserve contractions**\n",
    "tokens = tokenize(example)\n",
    "\n",
    "#take out semantic information\n",
    "no_semantics = remove_semantics(tokens)\n",
    "\n",
    "#strip punctuation\n",
    "no_punct = strip_punctuation(no_semantics)\n",
    "\n",
    "#convert to lowercase\n",
    "lower = lower_case(no_punct)\n",
    "\n",
    "#remove stopwords\n",
    "no_stops = remove_stopwords(lower)\n",
    "\n",
    "#remove numbers from tokens\n",
    "words = remove_numbers(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Input:\n",
      " <semantics> This   &is [an] ExAmPlE? {of} 45 string. with.? <sigh> [] punctuation, [laugh] by stopwordS and whitespace.    Can't wait!!!! \n",
      "\n",
      "Tokenize:\n",
      " ['<semantics>', 'This', '&is', '[an]', 'ExAmPlE?', '{of}', '45', 'string.', 'with.?', '<sigh>', '[]', 'punctuation,', '[laugh]', 'by', 'stopwordS', 'and', 'whitespace.', \"Can't\", 'wait!!!!'] \n",
      "\n",
      "Remove Semantic Info:\n",
      " ['This', '&is', 'ExAmPlE?', '{of}', '45', 'string.', 'with.?', 'punctuation,', 'by', 'stopwordS', 'and', 'whitespace.', \"Can't\", 'wait!!!!'] \n",
      "\n",
      "Remove Punctuation:\n",
      " ['This', 'is', 'ExAmPlE', 'of', '45', 'string', 'with', 'punctuation', 'by', 'stopwordS', 'and', 'whitespace', 'Cant', 'wait'] \n",
      "\n",
      "Lowercase:\n",
      " ['this', 'is', 'example', 'of', '45', 'string', 'with', 'punctuation', 'by', 'stopwords', 'and', 'whitespace', 'cant', 'wait'] \n",
      "\n",
      "Remove Stopwords:\n",
      " ['example', '45', 'string', 'punctuation', 'stopwords', 'whitespace', 'cant', 'wait'] \n",
      "\n",
      "Final:\n",
      " ['example', 'string', 'punctuation', 'stopwords', 'whitespace', 'cant', 'wait'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Raw Input:\\n', example, '\\n')\n",
    "print('Tokenize:\\n', tokens, '\\n')\n",
    "print('Remove Semantic Info:\\n', no_semantics, '\\n')\n",
    "print('Remove Punctuation:\\n', no_punct, '\\n')\n",
    "print('Lowercase:\\n', lower, '\\n')\n",
    "print('Remove Stopwords:\\n', no_stops, '\\n')\n",
    "print('Final:\\n', words, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
